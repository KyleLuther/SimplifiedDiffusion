{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAFz3cyzg5ey"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision, torch.nn as nn, torch.nn.functional as F\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "import copy\n",
        "\n",
        "#########\n",
        "# data: MNIST, standardize to ~zero mean/unit variance, and pad to 32x32 pixels\n",
        "#########\n",
        "tform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Pad(2),\n",
        "    torchvision.transforms.Normalize(0.1003, 0.2756)])\n",
        "dataset = torchvision.datasets.MNIST(root='.', transform=tform, download=True)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "#########\n",
        "# model: UNet with noise conditioning\n",
        "#########\n",
        "class NoiseConditionalBlock(nn.Module):\n",
        "    def __init__(self, fts, embed_dim=128):\n",
        "        super().__init__()\n",
        "        self.normactconv1 = nn.Sequential(nn.GroupNorm(8, fts), nn.ELU(), nn.Conv2d(fts, fts, kernel_size=3, padding=1))\n",
        "        self.normactconv2 = nn.Sequential(nn.GroupNorm(8, fts), nn.ELU(), nn.Conv2d(fts, fts, kernel_size=3, padding=1))\n",
        "        self.affine = nn.Linear(embed_dim, 2*fts) # FiLM-like affine normalization layer https://arxiv.org/pdf/1709.07871.pdf\n",
        "\n",
        "    def forward(self, x, emb):\n",
        "        residual = x\n",
        "        x = self.normactconv1(x)\n",
        "        scale, shift = torch.chunk(self.affine(emb)[:,:,None,None], 2, 1)\n",
        "        x = x * (1+scale) + shift # noise-dependent rescaling of fts maps\n",
        "        x = self.normactconv2(x)\n",
        "        return x + residual\n",
        "\n",
        "class NoiseConditionalUNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=3, embed_dim=128, features=[32,64,128,256,256]):\n",
        "        super().__init__()\n",
        "        self.emb_weight  = nn.Parameter(2 * np.pi * np.sqrt(embed_dim) * torch.rand(embed_dim), requires_grad=False)\n",
        "        self.in_conv     = nn.Conv2d(in_channels, features[0], kernel_size=3, padding=1)\n",
        "        self.out_conv    = nn.Conv2d(features[0], out_channels, kernel_size=3, padding=1)\n",
        "\n",
        "        self.down_blocks = nn.ModuleList([NoiseConditionalBlock(fts, embed_dim) for fts in features])\n",
        "        self.up_blocks   = nn.ModuleList([NoiseConditionalBlock(fts, embed_dim) for fts in features])\n",
        "        self.downsamples = nn.ModuleList([nn.Conv2d(f_in, f_out, kernel_size=2, stride=2) for f_in, f_out in zip(features[:-1],features[1:])])\n",
        "        self.upsamples   = nn.ModuleList([nn.ConvTranspose2d(f_out, f_in, kernel_size=2, stride=2) for f_in, f_out in zip(features[:-1],features[1:])])\n",
        "\n",
        "    def forward(self, x, sigmas):\n",
        "         # convert noise level to tensor if necessary\n",
        "        if type(sigmas) is not torch.Tensor:\n",
        "          sigmas = torch.tensor(sigmas).float().unsqueeze(0).to(x.device)\n",
        "\n",
        "        # map noise-level to a higher-dim embedding via a random matrix multiply\n",
        "        sigma_emb = ((sigmas/(1+sigmas**2).sqrt())[:,None] * self.emb_weight).sin()\n",
        "\n",
        "        # rescale the inputs\n",
        "        x = x/(1+sigmas.view(-1,1,1,1)**2).sqrt()\n",
        "\n",
        "        x  = self.in_conv(x)\n",
        "        x0 = self.down_blocks[0](x, sigma_emb)\n",
        "        x1 = self.down_blocks[1](self.downsamples[0](x0), sigma_emb)\n",
        "        x2 = self.down_blocks[2](self.downsamples[1](x1), sigma_emb)\n",
        "        x3 = self.down_blocks[3](self.downsamples[2](x2), sigma_emb)\n",
        "        x4 = self.down_blocks[4](self.downsamples[3](x3), sigma_emb)\n",
        "        x  = self.up_blocks[3](x3 + self.upsamples[3](x4), sigma_emb)\n",
        "        x  = self.up_blocks[2](x2 + self.upsamples[2](x), sigma_emb)\n",
        "        x  = self.up_blocks[1](x1 + self.upsamples[1](x), sigma_emb)\n",
        "        x  = self.up_blocks[0](x0 + self.upsamples[0](x), sigma_emb)\n",
        "        x  = self.out_conv(x)\n",
        "        return x\n",
        "\n",
        "#########\n",
        "# generation: we diffuse with an exponentially decaying noise level (details in readme.md)\n",
        "#########\n",
        "# in short, we start with random noise then iterate:\n",
        "# 1. subtract some fraction of predicted noise (alpha sigma eps_hat)\n",
        "# 2. reinject some new amount of noise (beta sigma z)\n",
        "# 3. this reduces the noise level by a factor of sqrt((1-alpha)^2 + beta^2) (see https://arxiv.org/abs/2007.13640)\n",
        "# We stop once the noise level has decayed below a threshold sigma_min\n",
        "@torch.no_grad()\n",
        "def generate_samples(model, sigma=30.0, sigma_min=0.03, alpha=0.1, beta=.40, shape=(64,1,32,32), device='cuda'):\n",
        "    x = sigma * torch.randn(shape, device=device)\n",
        "    xs = [x.cpu()]\n",
        "    while sigma > sigma_min:\n",
        "        x = x - alpha * sigma * model(x,sigma) + beta * sigma * torch.randn_like(x)\n",
        "        sigma = sigma * np.sqrt((1-alpha)**2 + beta**2) # noise decays exponentially\n",
        "        xs.append(x.cpu()) # save all intermediate generations\n",
        "\n",
        "    return torch.stack(xs) # (nsteps, batch, channels, height, width)\n",
        "\n",
        "#########\n",
        "# visualization utils\n",
        "#########\n",
        "def show_grid(x, title=''):\n",
        "    plt.figure(figsize=(12,3), dpi=100)\n",
        "    img = torchvision.utils.make_grid(x, nrow=16).permute(1,2,0).cpu()\n",
        "    plt.imshow((img-img.min()) / (img.max()-img.min()))\n",
        "    plt.title(title); plt.xticks([]); plt.yticks([])\n",
        "    plt.show()\n",
        "\n",
        "#########\n",
        "# training: we just train the UNet to denoise images with multiple levels of added noise\n",
        "#########\n",
        "losses = []\n",
        "sigma_min, sigma_max = 0.03, 100.0  # lowest and highest noise-to-signal ratio we train the network on\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = NoiseConditionalUNet(1,1).to(device)\n",
        "model_ema = copy.deepcopy(model) # keep an exponentially weighting moving average\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "for epoch in range(50):\n",
        "    for x, y in (pbar:=tqdm(dataloader, desc=f'epoch {epoch}/{50}')):\n",
        "        optim.zero_grad()\n",
        "        x = x.to(device)\n",
        "\n",
        "        # noisify input\n",
        "        #   noise levels are chosen from log-uniform distribution between sigma_min and sigma_max\n",
        "        #   noise levels ranges from \"looks uncorrupted\" to \"looks like pure noise\"\n",
        "        #   this distribution can be modified for improved generation performance\n",
        "        sigmas = sigma_max * (sigma_min/sigma_max) ** torch.rand(x.shape[0],device=device)\n",
        "        epsilon = torch.randn_like(x).to(device)\n",
        "        x_noisy = x + sigmas.view(-1,1,1,1) * epsilon\n",
        "\n",
        "        # noise prediction loss: mean squared error between noise and network output\n",
        "        loss = ((epsilon - model(x_noisy, sigmas))**2).mean()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        # exponential moving average of the weights\n",
        "        # can be surprisingly helpful for stabilizing generations\n",
        "        # Even when the loss curves look normal, generations seemingly randomly will look terrible.\n",
        "        for ema_v, model_v in zip(model_ema.state_dict().values(), model.state_dict().values()):\n",
        "            ema_v.copy_(0.999 * ema_v + 0.001 * model_v)\n",
        "\n",
        "        # logging\n",
        "        losses.append(loss.item())\n",
        "        pbar.set_postfix({'loss': np.mean(losses[-100:])}) # average of last 100 losses\n",
        "\n",
        "    # generate and visualize images every epoch\n",
        "    display.clear_output()\n",
        "    xs = generate_samples(model.eval(), sigma=sigma_max, sigma_min=sigma_min, alpha=0.1, beta = 0.35)\n",
        "    show_grid(xs[-1], f'epoch={epoch} \\n generated images')\n",
        "\n",
        "    xs = generate_samples(model_ema.eval(), sigma=sigma_max, sigma_min=sigma_min, alpha=0.1, beta = 0.35)\n",
        "    show_grid(xs[-1], 'generated images from exponential moving average network')\n",
        "\n",
        "    show_grid(xs[::16,0]/xs[::16,0].std(dim=(1,2,3),keepdim=True), f'one generation trajectory (total sampling steps = {len(xs)})')\n",
        "    show_grid(x[:32], 'real images')\n",
        "    show_grid(x_noisy[:32] / (1+sigmas[:32].view(-1,1,1,1)**2).sqrt(), 'noisy images we train on')\n",
        "    plt.plot(losses)\n",
        "    plt.yscale('log'); plt.xlabel('iter'); plt.title('training loss')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NpR7ORz41z0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}